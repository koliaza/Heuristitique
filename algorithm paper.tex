%% LyX 2.0.5 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass{article}
\usepackage{mathpazo}
\renewcommand{\familydefault}{\rmdefault}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},backref=section,colorlinks=false]
 {hyperref}
\begin{document}

\title{An heuristic for graph isomorphisms}


\author{Nguy\~{\^e}n Lê Thành D\~ung \and  Blanchard Nicolas Koliaza}

\maketitle

\section*{Foreword }

The problem considered is the graph isomorphism (GI) problem : given
two graphs $G$ and $G'$, can one compute an isomorphism between
them. The original goal was to implement the Weisfeiler-Lehman heuristic
in the C programming language, but we chose to implement our own heuristic
(named PN for Path-Neighbour) to test its performance. The main goal
was to find an heuristic which would behave polynomially on a bigger
subset of problems, even if the polynomial degree increases. 

\tableofcontents{}


\section{First Considerations}

We adopt the notations of graphs with n vertices and m edges. $G(n,p)$
denotes the graph generated through the Erdös-Rényi model with n vertices
and probability p for each edge. 

There is a strong link between GI and algebra : finding an isomorphism
is the same as finding a basis in which the adjacency matrix of G
becomes that of G'. Testing all solutions is equivalent to testing
all permutations and a naive algorithm would take $n!$ operations.
The GI problem lies between the complexity classes P and NP and Schöning
\cite{Schoening1988} proved that it is not NP-complete unless $P=NP$.
However, no polynomial solution has been found and the best deterministic
algorithm so far is due to Eugene Luks and runs in $2^{O(\sqrt{n\, logn})}$\cite{Babai1983}.
However some efficient heuristics are available, including \emph{nauty}
and \emph{conauto}, which runs in $O(n^{5})$ with very high probability
for any graph in $G(n,p)$\cite{Lopez-Presa2009}. In our algorithm
and test we often consider multi-graphs, as the hard cases are much
easier to generate for multi-graphs and the difference has no impact
on our heuristic. Finally, we tried to make an heuristic which would
behave well when launched on p different graphs to check if any two
are isomorphic.


\section{The Heuristics}


\subsection{The Weisfeiler-Lehman heuristic}

The original Weisfeiler-Lehman (WL) heuristic works by coloring the
edges of a graph according to the following rules :
\begin{itemize}
\item We begin with a coloring that assigns to every vertex the same color
(this is the 1-dimensional version).
\item At each pass, the color of each vertex is determined by the number
of neighbours of color c for each c.
\item After at most n passes, the colors don't change anymore.
\end{itemize}
These rules actually only produce a certificate of non-isomorphism.
To construct an isomorphism using WL one uses backtracking coupled
with the fact that the image of a vertex has to be of the same color.
It is easy to see that two isomorphic graphs behave in the same way
when subject to WL coloring, but the converse does not generally hold.
Notably, some special classes of graphs make backtracking omnipresent,
e.g. in k-regular graphs, thus leading to time complexity up to $O(n^{n})$.
The heuristic can be improved by changing the initial coloring of
the vertices, but we shall only study this case.


\subsection{The PN heuristic}


\subsubsection{The idea}

PN is based on the following property : 

Let $N_{k}(x)$ be the number of neighbours at distance exactly k
from x, and $P_{k}(x)$ the number of paths of length k starting from
x, then if $f$ is an isomorphism between $G$ and $G'$ , $N_{k}(x)=N_{k}(f(x))$
and $P_{k}(x)=P_{k}(f(x))$. Thus, by computing the different $N_{x}$
and $P_{x}$ we can prune the search tree and limit the possibilities.
We name the array of couples $P_{k}(x),N_{k}(x)$ for k between 1
and n PN(x), and compute an array containing PN(x) for each x, obtaining
the PN arrays. 


\subsubsection{Structure of the algorithm}

The algorithm we use actually incorporates multiple testing phases
to quickly eliminate easy cases. It can be decomposed in the following
steps : 
\begin{enumerate}
\item Input parsing and choice of data structure
\item Primary test phase
\item Construction of each PN-array 
\item Sorting of the PN-arrays
\item Comparison of the PN-arrays 
\item Comparison of the neighbours of compatible vertices
\item If possible construction of an isomorphism by refined bruteforce
\end{enumerate}

\subsubsection{Details }

We keep the list of image-possibilities for all vertices in a matrix
form. When one line or column becomes full of zeroes, we have a negative
certificate. The matrix actually corresponds to classes of an equivalence
relation, and every class of cardinal c has at most $c!$ possibilities
of isomorphism. When the product of the $c!$ becomes small, bruteforce
becomes possible. The goal of the PN matrix is to separate the vertices
in as many classes as possible, but bruteforce can sometimes be used
earlier, as is the case in the primary test phase. However, when one
computes the PN arrays, it is not always enough, and so we use a technique
from WL and compare the immediate neighbourhood of each vertex to
see if it is compatible with all of its images, to prune some more. 


\subsubsection{Primary test phase }

The problem with the naive algorithm is that the number of possibilities
grows exponentially in n, however, when one considers permutations
which are composed of one transposition, there are at most $n^{2}$possibilities
and each take at most $m$ operations. The first test phase uses different
simple techniques to quickly find a certificate of non-isomorphism
or an easy isomorphism when doing so is possible. The tests are run
in this order : 
\begin{enumerate}
\item Check for equality between the matrices
\item Check size and number of connected components
\item Compare the list of degrees and record the number of possibilities
\item When the number of possibilities is small ($O(n^{2})$) use bruteforce
\item Still check for simple transpositions when it is not the case
\end{enumerate}

\section{Tests and Benchmark}

We have included different basic test generation programs, depending
on the model : 


\subsection{Random generation}
\begin{itemize}
\item The Erdös-Rényi $G(n,p)$ model with probability p for each edge works
in general quite fast because the probability that two graphs are
not isomorphic (and trigger a certificate) is very high. 
\item The similar model with $G(n,M)$ behaves the same way.
\item A model to generate random k-regular multigraphs that generates k
random permutations of n vertices and links each vertice of the initial
array to each of its images in the resulting permutations. 
\end{itemize}
All other methods so far for generating k-regular graphs (and not
multigraphs) are probabilistic except for very small k, and when $k\ge log(n)$
have exponential expected time \cite{Wormwald:UniformGeneration},
so we restricted ourselves to those three models, as our algorithm
should work as well on multigraphs as on normal graphs.


\subsection{Isomorphic graph generation}

To generate two isomorphic graphs is actually really easy : as two
graphs are isomorphic if and only if their adjacency matrices are
similar, one has to compute a random permutation (which corresponds
to a change of basis), and to apply it to any graph to obtain an isomorphic
copy. We generate those from all three different models of random
graphs already implemented. 


\subsection{Benchmark}

\pagebreak{}


\section{Comparison with Weisfeiler-Lehman}


\subsection{Proof}

Our goal here is to show that the subset of problems solved in polynomial
time by WL is strictly included in the subset solved by our heuristic.
We shall consider an extended version of WL (EWL) to facilitate the
proof, where colors aren't redistributed among $[1;n]$ but are instead
an injective function of the vertex's previous color and the multiset
of its neighbours' colors into the set of colors (which is not anymore
included in $[1;n]$). Two cases allow WL to reduce the number of
possibilities and hence have a polynomial runtime : the first is when
the colorings of G and G' are incompatible, and the second when there
is a color shared by an unique vertex in each graph. 

We must show three properties : 
\begin{itemize}
\item When the graphs are isomorphic, WL, EWL and PN compute the isomorphism,
and produce a negative certificate in the other case (correctness)
\item When WL finds two incompatible coloring, then so does EWL, and PN
also gives a negative certificate (polynomial negative certificate)
\item When WL colors a vertex in an unique color in both graphs, then EWL
does the same, and our algorithm also recognizes that those two vertices
must be linked if the graphs are isomorphic (polynomial isomorphism)
\end{itemize}
The first is immediate, because the operations we use are invariant
through permutations of the vertices, hence if the two graphs are
isomorphic it might take exponential time but will surely end. The
two other properties trivially hold for extended WL, and we must show
that it implies that they hold for PN. However, there is an advantage
of EWL over WL, because the coloring is unique for the two graphs
(it being injective), so if there is exactly one vertex in each graph
colored by C, then the isomorphism must assign one to the other (problems
may arise in WL because the coloring is not necessarily injective).
This gives an easy proof of the third depending on the second, because
the fact that a vertex is colored uniquely in G and G' is implied
by the fact that it is colored differently from every single other
vertex. Hence we must only prove the second property.

We shall proceed by induction to prove that if EWL colors a vertice
in G and another in G' in different colors at run k, then PN also
allows us to differentiate those two vertices. 

At the first run of the coloring, every vertex is colored by its degree
so it is trivially true. 

Now let us suppose that the property holds at run k, and show that
it holds at run k+1 : 

Consider two vertices V and W (one per graph) that had the same color
for all previous runs, but which are colored differently at run k+1.
Then their neighbourhoods are incompatible, which means that the multiset
of colors is not the same, so there is a color c such that there is
one more vertex of color c in N(V) than in N(W). However, those colors
were attributed at run k, so it means that when comparing the lists
of neighbours of V and W in PN, those lists will be incompatible by
hypothesis. Hence V and W can't be linked in PN, which ends the induction. 


\subsection{Complexity analysis}

As the GI problem isn't known to be in P, it is not absurd to have
a worst running time of $O(n!)$. However, we can go into details
and see that in most cases the real running time is generally much
lower. 

The reading phase takes at least $O(m)$, but is implemented in $O(n^{2})$
as we use matrices. 

The first test phase consists of a list of at most five tests of increasing
time complexity, to quickly solve cases of increasing difficulty. 

The first three tests run in $O(n^{2})$ although they could be implemented
in $O(m+n*log(n))$. 

The two other tests take at most $O(n^{4})$ but only $O(n^{2}m)$
when run on lists. However, even though this polynomial is of high
degree, it does not effectively take as much time because most of
the tests fail immediately, hence its presence before PN has an utility. 

The most time-consuming phase is the array generation. It does n multiplications
of $n*n$ matrices for each graph, which takes $O(n^{4})$ and a sort
after that (which takes at most $O(n^{2}log(n))$). We could have
used Strassen to decrease that cost but the overhead on small matrices
reduces its interest. 

The next phase is the comparison of the arrays. It takes at most $O(n^{2})$,
and when we also check compatibility with the neighbours we obtain
$O(n^{3})$.

If we haven't found an isomorphism or a negative certificate by then
we launch a bruteforce on the remaining possibilities, which at worst
runs in $O(n!)$. 

A quick analysis of WL gives a higher bound (in polynomial cases)
of $O(mn^{2})$ when implemented with adjacency lists although the
expected running time is lower. We can then separate the problems
in four categories : 
\begin{enumerate}
\item The very simple ones that are solved much faster by PN thanks to the
primary test phase
\item The medium-easy cases that are solved by PN but not the primary test
phase, and where WL is asymptotically better
\item The medium-hard cases that are solved polynomially by PN but exponentially
by WL
\item The hard cases where both algorithms behave exponentially. 
\end{enumerate}
We see that we could improve PN by adding WL between the first test
phase and the array generation, but the overhead would once more increase.
Also, every information we gather doing initial tests can be used
by the following ones, which wouldn't be the case with WL (it would
use the previous ones but would have no impact on the following ones). 


\section{Implementation and Optimization}


\subsection{Data Structures}

The choice of data structures varies between adjacency matrix and
list, and sometimes both, and allows us to take advantage of faster
algorithms on sparse graphs using lists, while allowing us to know
in O(1) if two vertices are linked. 

The construction of the PN-array is generally the most time-expensive
task, it is mostly done by multiplication of the adjacency matrix.
Sorting the PN-array is easily done with a heapsort. 

The construction of the isomorphism is done by trying to assign to
an x an y such that$N(x)=N(y)$ and backtracking when unsuccessful. 


\subsection{Function Optimization}

As with many graph algorithms, PN can be improved by using adjacency
lists in the case of sparse graphs. However, that seldom changes the
asymptotic complexity, as the PN-array generation can only benefit
from it in case of graphs with very poor expansion properties. The
list representation is mostly used in the primary test phase, where
it allows us to have tests in $O(m)$ instead of $O(n^{2})$. Optimization
on the matrix operations cannot really be done in practice as Strassen's
algorithm has no interest on the matrix size we generally consider.
However we took care of memory locality in their representation, which
might improve the performance in practice. 


\subsection{Parallelism}

The advantage of the PN-arrays is that they can be generated in a
completely independent fashion, and so are easy to parallelize. By
default we create a different thread for each graph, which gives a
speed-up ratio close to 2 in the basic case, but that can grow up
to the number of cores when launched on a set of graphs. This is an
advantage of PN over WL as the threads do not have to communicate,
while the latter has to do some comparisons between each coloring
at each run, requiring constant interaction between threads.

\bibliographystyle{plain}
\bibliography{\string"bibliography algorithms\string"}

\end{document}
